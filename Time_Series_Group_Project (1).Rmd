---
title: "Time_Series_Group_Project"
author: "Xavier Bryant, Adrian"
date: "24/03/2021"
output: pdf_document
---

```{r setup, include=FALSE}
install.packages("forecast")
knitr::opts_chunk$set(echo = TRUE)
library(tsoutliers)
library(knitr)
library(fpp2)
library(SWMPr)
library(forecast)
library(dygraphs)
library(dplyr)
library(TSstudio)
```


# Introdcution


We use the Boston marathon data from.. 

so original from: https://www.baa.org/races/boston-marathon/results/champions

and inspired by: https://otexts.com/fpp2/nonlinear-regression.html


load the data:


```{r}
marathon <- marathon # the time series is already defined as can be seen below
```





# First model 


We can see that the data lasts from 1897 to 2016 and is on a yearly basis. we can see an overall decrease in the running times, which makes


```{r}
plot(marathon, main = "Basic Plot of Marathon Data")
```
here we seperated the whole time series into 3 parts 
```{r}
marathonts1<-ts(marathon[1:25],start=c(1897),end=c(1923),freq=1)
marathonts2<-ts(marathon[25:56],start=c(1923),end=c(1953),freq=1)
marathonts3<-ts(marathon[56:120],start=c(1953),freq=1)
plot(marathonts1,main="the basic plot of first part of marathon time series")
plot(marathonts2,main="the basic plot of second part of marathon time series")
plot(marathonts3,main="the basic plot of third part of marathon time series")
```

plot the acf and pacf plots of each part 
```{r}
par(mfrow=c(1,2))
acf(marathonts1,lag=150)
pacf(marathonts1,lag=150)
acf(marathonts2,lag=150)
pacf(marathonts2,lag=150)
acf(marathonts3,lag=150)
pacf(marathonts3,lag=150)
```

the analysis of the first part of marathon
```{r}
par(mfrow=c(1,2))
lmarathonts1 <- log(marathonts1)
plot(lmarathonts1)+title("plot of first part of log_marathon ")
dlmarathonts1 <- diff(lmarathonts1)
plot(dlmarathonts1)+title("plot of first part of marathon of diff1 ")
acf(dlmarathonts1, lag=150)
pacf(dlmarathonts1, lag=150)
Box.test(lmarathonts1, type="Ljung-Box")
ts_lags(lmarathonts1)
auto.arima(lmarathonts1, ic="aic")
tso(lmarathonts1, types = c("A0", "LS", "TC", "IO", "SLS"))
tso(lmarathonts1, types = c("A0", "LS", "TC"))
outmarathonts1 <- tso(lmarathonts1, types = c("A0", "LS", "TC")) 
plot(outmarathonts1)
#with outliers
par(mfrow=c(2,2))
plot(outmarathonts1$yadj)
plot(diff(outmarathonts1$yadj))
acf(diff(outmarathonts1$yadj), lag=150)
pacf(diff(outmarathonts1$yadj), lag=150)
auto.arima(outmarathonts1$yadj, ic="aic")
#PARAMETER ESTIMATION WITH CSS-ML
arima(x = marathonts1, order=c(0,1,1), method = "CSS-ML")
arima(x = lmarathonts1, order=c(0,1,1), method = "CSS-ML")
arima(x = diff(lmarathonts1), order=c(0,0,1), method = "CSS-ML")
#forecast
par(mfrow=c(1,1))
outmarathonts1$yadj %>%
  forecast(h=36) %>%
  {cbind(actuals=.$x, forecast_mean=.$mean,
         lower_95=.$lower[,"95%"], upper_95=.$upper[,"95%"],
         lower_80=.$lower[,"80%"], upper_80=.$upper[,"80%"])} %>%
  dygraph() %>%
  dySeries("actuals", color = "black") %>%
  dySeries(c("lower_80", "forecast_mean", "upper_80"),
           label = "80%", color = "blue") %>%
  dySeries(c("lower_95", "forecast_mean", "upper_95"),
           label = "95%", color = "blue")
x=marathonts1
fit<-arima(x,order=c(0,1,1),include.mean=FALSE)
forecast<-predict(fit,n.ahead=50)
pm <- forecast(fit, h=12)
plot(pm)
```

the analysis of the second part of marathon
```{r}
par(mfrow=c(1,2))
lmarathonts2 <- log(marathonts2)
plot(lmarathonts2)+title("plot of second part of log_marathon ")
dlmarathonts2 <- diff(lmarathonts2)
plot(dlmarathonts2)+title("plot of second part of marathon of diff1 ")
acf(dlmarathonts2, lag=150)
pacf(dlmarathonts2, lag=150)
Box.test(lmarathonts2, type="Ljung-Box")
ts_lags(lmarathonts2)
auto.arima(lmarathonts2, ic="aic")
tso(lmarathonts2, types = c("A0", "LS", "TC", "IO", "SLS"))
tso(lmarathonts2, types = c("A0", "LS", "TC"))
outmarathonts2 <- tso(lmarathonts2, types = c("A0", "LS", "TC")) 
plot(outmarathonts2)
#with outliers
par(mfrow=c(2,2))
plot(outmarathonts2$yadj)
plot(diff(outmarathonts2$yadj))
acf(diff(outmarathonts2$yadj), lag=150)
pacf(diff(outmarathonts2$yadj), lag=150)
auto.arima(outmarathonts2$yadj, ic="aic")
#PARAMETER ESTIMATION WITH CSS-ML
arima(x = marathonts2, order=c(0,1,1), method = "CSS-ML")
arima(x = lmarathonts2, order=c(0,1,1), method = "CSS-ML")
arima(x = diff(lmarathonts2), order=c(0,0,1), method = "CSS-ML")
#forecast
par(mfrow=c(1,1))
outmarathonts2$yadj %>%
  forecast(h=36) %>%
  {cbind(actuals=.$x, forecast_mean=.$mean,
         lower_95=.$lower[,"95%"], upper_95=.$upper[,"95%"],
         lower_80=.$lower[,"80%"], upper_80=.$upper[,"80%"])} %>%
  dygraph() %>%
  dySeries("actuals", color = "black") %>%
  dySeries(c("lower_80", "forecast_mean", "upper_80"),
           label = "80%", color = "blue") %>%
  dySeries(c("lower_95", "forecast_mean", "upper_95"),
           label = "95%", color = "blue")
x=marathonts2
fit<-arima(x,order=c(0,1,1),include.mean=FALSE)
forecast<-predict(fit,n.ahead=50)
pm <- forecast(fit, h=12)
plot(pm)
```

the analysis of the third part of marathon
```{r}
par(mfrow=c(1,2))
lmarathonts3 <- log(marathonts3)
plot(lmarathonts3)+title("plot of third part of log_marathon ")
dlmarathonts3 <- diff(lmarathonts3)
plot(dlmarathonts3)+title("plot of third part of marathon of diff1 ")
acf(dlmarathonts3, lag=150)
pacf(dlmarathonts3, lag=150)
Box.test(lmarathonts3, type="Ljung-Box")
ts_lags(lmarathonts3)
auto.arima(lmarathonts3, ic="aic")
tso(lmarathonts3, types = c("A0", "LS", "TC", "IO", "SLS"))
tso(lmarathonts3, types = c("A0", "LS", "TC"))
outmarathonts3 <- tso(lmarathonts3, types = c("A0", "LS", "TC")) 
plot(outmarathonts3)
#with outliers
par(mfrow=c(2,2))
plot(outmarathonts3$yadj)
plot(diff(outmarathonts3$yadj))
acf(diff(outmarathonts3$yadj), lag=150)
pacf(diff(outmarathonts3$yadj), lag=150)
auto.arima(outmarathonts3$yadj, ic="aic")
#PARAMETER ESTIMATION WITH CSS-ML
arima(x = marathonts3, order=c(0,1,1), method = "CSS-ML")
arima(x = lmarathonts3, order=c(0,1,1), method = "CSS-ML")
arima(x = diff(lmarathonts3), order=c(0,0,1), method = "CSS-ML")
#forecast
par(mfrow=c(1,1))
outmarathonts3$yadj %>%
  forecast(h=36) %>%
  {cbind(actuals=.$x, forecast_mean=.$mean,
         lower_95=.$lower[,"95%"], upper_95=.$upper[,"95%"],
         lower_80=.$lower[,"80%"], upper_80=.$upper[,"80%"])} %>%
  dygraph() %>%
  dySeries("actuals", color = "black") %>%
  dySeries(c("lower_80", "forecast_mean", "upper_80"),
           label = "80%", color = "blue") %>%
  dySeries(c("lower_95", "forecast_mean", "upper_95"),
           label = "95%", color = "blue")
x=marathonts3
fit<-arima(x,order=c(0,1,1),include.mean=FALSE)
forecast<-predict(fit,n.ahead=50)
pm <- forecast(fit, h=12)
plot(pm)
```

Now reviewing the stationarity of the plot we see that the plot is not stationary reviewin the acf and the pacf:



```{r}
acf(marathon, lag=150)
pacf(marathon, lag=150)
```

At first look it appears that there is non-stationarity with the slow decrease in the ACF, which then increases again. We also have a some what decaying patten in the PACF, reminiscent of an MA, but there is some odd patterns. There is also several significant peaks. We will try to make our trend weakly stationary for our analysis.

Reffering to our original plot, we will then take the log as we see that variance appears to be  dfferent throughout the series.


```{r}
lmarathon <- log(marathon)
plot(lmarathon)
#maybe think about adding the trend line here. not sure if it's possible.
```




We then can see that there is still in series, downward, that we need to remove, with the first difference to get the log return. looks like non linear trend. also, changes throughout or piecewise changes.



```{r}
dlmarathon <- diff(lmarathon)
plot(dlmarathon)
# if log-transformed is differenced with lag 1, we obtain the so-called log-return
```



There is none constant deadlines. variance appears constant except in the 1910s (?) for the log return series. 



```{r}
acf(dlmarathon, lag=150)
pacf(dlmarathon, lag=150)
```


We see there's a decaying patttern in the first few peaks, of the AR (or MA), and then two significant peaks in the PACF. difficult to diagnose at the moment. This is tough to tell, although, it's likely we don't have white noise, as we have some significant peaks, we'd like to check if we have a relationship in our data with the Box-Ljung test.




```{r}
Box.test(lmarathon, type="Ljung-Box") 
```



Extremely small p-value so we definitely have a relationship with the past valeus (not white noise?). We can see this through the lag values representation. A definite relationship with past values, with the lags. We can see some almost linear relationships. It does get slightly weaker over time but is still visibly apparent. actually a representativion of the pacf.




```{r}
#lag.plot(lmarathon, lags = 4) #other methods
ts_lags(lmarathon) 
#lagPlot(lmarathon) #other mehods
```





```{r}
# decompose(marathon) #CANT GET IT TO WORK AT THE MOMENT (NO SEASONAL TREND), ATTEMPT TO SEPERATE TREND FROM RANDOM MOVEMENT, WOULD BE NICE THOUGH
```

```{r}
#CAN'T FIGURE IT OUT: https://anomaly.io/seasonal-trend-decomposition-in-r/index.html
#ts_marathon = ts(marathon, frequency = 1)
#decompose_marathon = decompose(ts_marathon, "multiplicative")
 
#plot(as.ts(decompose_marathon$seasonal))
#plot(as.ts(decompose_marathon$trend))
#plot(as.ts(decompose_marathon$random))
#plot(decompose_marathon)
```


We now will try to identify our model. 


```{r}
auto.arima(lmarathon, ic="aic")
```

Means we have to take one difference.

doesn't really look like an an MA in the ACF and PACF

We then identify our model without outliers below. We first try to find all outliers.



```{r}
tso(lmarathon, types = c("A0", "LS", "TC", "IO", "SLS")) #DON'T TAKE FIRST DIFFERENCE?
```


It defines three IOs which in our context, are difficult to find the logic with as a endogenous change, running capacity doesn't change. There is also no Seasonal outliser so we remove those. IOs often overdefined too for LSs.


```{r}
tso(lmarathon, types = c("A0", "LS", "TC"))
```



We see a few changes. Taking out the outliers we see tht the trend is more smooth. 1921 and 1953 we know that the track changes.


```{r}
outmarathon <- tso(lmarathon, types = c("A0", "LS", "TC")) #considered all the types of outlier possible

plot(outmarathon)
```


Now we will estimating the parameters.

COULD DO ACF, PACF on the 


```{r} 
# TRY TO GET ACF AND PACF WITH THE OUTLIERS
plot(outmarathon$yadj)
plot(diff(outmarathon$yadj))
acf(diff(outmarathon$yadj), lag=150)
pacf(diff(outmarathon$yadj), lag=150)
auto.arima(outmarathon$yadj, ic="aic")
```




```{r}
#PARAMETER ESTIMATION WITH CSS-ML
arima(x = marathon, order=c(0,1,1), method = "CSS-ML")
arima(x = lmarathon, order=c(0,1,1), method = "CSS-ML")
arima(x = diff(lmarathon), order=c(0,0,1), method = "CSS-ML") #honestly doesn't really change that much

#down bias of estimate important to mention
```

so the -0.6492 is the theta. 














```{r}
#abs(polyroot(c(-0.69))) #NO POINT SINCE WE HAVE ONE
```


## FORECASTS OF FIRST MODEL

```{r}
outmarathon$yadj %>%
  forecast(h=36) %>%
  {cbind(actuals=.$x, forecast_mean=.$mean,
         lower_95=.$lower[,"95%"], upper_95=.$upper[,"95%"],
         lower_80=.$lower[,"80%"], upper_80=.$upper[,"80%"])} %>%
  dygraph() %>%
  dySeries("actuals", color = "black") %>%
  dySeries(c("lower_80", "forecast_mean", "upper_80"),
           label = "80%", color = "blue") %>%
  dySeries(c("lower_95", "forecast_mean", "upper_95"),
           label = "95%", color = "blue")
```

```{r}
x=marathon
fit<-arima(x,order=c(0,1,1),include.mean=FALSE)
forecast<-predict(fit,n.ahead=50)
pm <- forecast(fit, h=12)
plot(pm)
```



~~~~~~RANDOM NOTES~~~~~


ARMA is built on this assumption: conditional mean is a (linear) function of past instances
of the series as well as past innovations.

Any of those weird equations we broke down?

obtain the parameters? Its MA so I think we need to use CSS and then MLE.

In order to be stationary, the unconditional mean and variance of the
MA(q) process should be constant. not sure it is


```{r}

# Kinda useless

#library(ggpmisc)
#ggplot(marathon, as.numeric = FALSE) + geom_line() + 
#  stat_peaks(colour = "red") +
#  stat_peaks(geom = "text", colour = "red", 
#            vjust = -0.5, x.label.fmt = "%Y") +
#  stat_valleys(colour = "blue") +
# stat_valleys(geom = "text", colour = "blue", angle = 45,
#              vjust = 1.5, hjust = 1,  x.label.fmt = "%Y")+
# ylim(-500, 7300)
```



## SECOND MODEL - SPLIT INTO THREE


```{r}
#could be a cool graph
library(ggfortify)
library(magrittr) # for piping %>%
library(dplyr)
library(changepoint)
# Plot ts objects
autoplot(marathon)
# Identify change points in mean and variance
marathon %>%
  changepoint::cpt.meanvar() %>%  # Identify change points
  autoplot()
# Detect jump in a data
strucchange::breakpoints(Nile ~ 1) %>%
  autoplot()
```

we note that there's actually three periods in the plot. there's varying course lengths: https://ade3.medium.com/bostons-evolution-1897-2018-cdd91aa79f95. We will check the relationship of the overall plot and the plot that's seperated but year. 

INCLUDE PLOT SEPERATED BY YEAR.




## THIRD MODEL - NON LINEAR 







